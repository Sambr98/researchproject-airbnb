{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to make Style estimations with Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import shapiro\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing style metrics and IMDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.read_csv(\"../data/london_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imd_per_ward = pd.read_csv(\"../data/imd_per_ward.csv\")[['WD17CD','Index of Multiple Deprivation (IMD) Score','Education, Skills and Training Score','Employment Score (rate)','Income Score (rate)']]\n",
    "imd_per_ward = imd_per_ward.rename(columns={\"Index of Multiple Deprivation (IMD) Score\": \"IMD\", \"Education, Skills and Training Score\" : \"IMD_Edu\", 'Employment Score (rate)' : 'IMD_Emp', 'Income Score (rate)': 'IMD_Inc'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_imd = metrics.merge(imd_per_ward, left_on=\"ward\", right_on=\"WD17CD\").drop(columns=['ward','WD17CD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = metrics_imd.drop(['IMD','IMD_Edu','IMD_Emp','IMD_Inc'],axis=1)\n",
    "y = metrics_imd[['IMD']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=list(X.columns))\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing forward stepwise selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X2 = sm.add_constant(X_scaled)\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwiseSelection(X, y):\n",
    "    features = list(X.columns)\n",
    "    overall_best_score = 0.0\n",
    "    features_slt = []\n",
    "    done = False\n",
    "    total_features = len(features)\n",
    "    counter = 0\n",
    "    \n",
    "    while (done == False):\n",
    "        best_score = 0.0\n",
    "        best_score_ft = None\n",
    "        \n",
    "        for i in features:\n",
    "            X_select = X_scaled[features_slt + [i]]\n",
    "            X2 = sm.add_constant(X_select)\n",
    "            est = sm.OLS(y, X2)\n",
    "            est2 = est.fit()\n",
    "            if (est2.rsquared_adj > best_score):\n",
    "                best_score = est2.rsquared_adj\n",
    "                best_score_ft = i\n",
    "        \n",
    "        if (best_score > overall_best_score):\n",
    "            features.remove(best_score_ft)\n",
    "            features_slt.append(best_score_ft)\n",
    "            overall_best_score = best_score\n",
    "            counter += 1\n",
    "        else:\n",
    "            done = True\n",
    "        \n",
    "        print(\"{}/{}\".format(counter, total_features), end='\\r')\n",
    "    \n",
    "    return features_slt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = stepwiseSelection(X_scaled, y)\n",
    "print(\"{} selected features :\".format(len(selected_features)))\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = X_scaled.copy()\n",
    "y_ = y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(n, features):\n",
    "    fit_rsquareds = []\n",
    "    RMSEs = []\n",
    "    MAEs = []\n",
    "    SCorrs = []\n",
    "    pVals = []\n",
    "    print(\"\\nResults ({} features) :\".format(len(features)))\n",
    "    for i in range(n):\n",
    "        # Splitting the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2)\n",
    "        X_train1 = X_train[features].copy()\n",
    "        X_test1 = X_test[features].copy()\n",
    "        # Fitting the model\n",
    "        X2 = sm.add_constant(X_train1)\n",
    "        est = sm.OLS(y_train, X2)\n",
    "        est2 = est.fit()\n",
    "        fit_rsquareds.append(est2.rsquared_adj)\n",
    "        # Making predictions\n",
    "        X2 = sm.add_constant(X_test1)\n",
    "        y_pred = est2.predict(X2)\n",
    "        # Storing the results\n",
    "        RMSEs.append((mean_squared_error(y_test, y_pred, squared=False)))\n",
    "        MAEs.append((mean_absolute_error(y_test, y_pred)))\n",
    "        SCorrs.append(stats.spearmanr(y_test.to_numpy().reshape(157,), y_pred.to_numpy())[0])\n",
    "        pVals.append(stats.spearmanr(y_test.to_numpy().reshape(157,), y_pred.to_numpy())[1])\n",
    "    # Storing and printing the results\n",
    "    df = pd.DataFrame()\n",
    "    df['Adjusted R2'] = fit_rsquareds\n",
    "    df['RMSE'] = RMSEs\n",
    "    df['MAE'] = MAEs\n",
    "    df['Spearman Correlation'] = SCorrs\n",
    "    print()\n",
    "    print(\"Mean Adjusted R2 when fitting : {}\".format(np.mean(fit_rsquareds)))\n",
    "    print()\n",
    "    print(\"Mean RMSE : {}\".format(np.mean(RMSEs)))\n",
    "    print(\"Mean MAE : {}\".format(np.mean(MAEs)))\n",
    "    print(\"Mean Spearman Correlation : {}\".format(np.mean(SCorrs)))\n",
    "    print(\"Mean P-Value : {}\".format(np.mean(pVals)))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_validate(200, selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the results to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"../data/temp_results/london_style_linear.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
