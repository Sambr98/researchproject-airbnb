{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to make baseline estimations, in the US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(inputs, labels, n, features, output_transforms=None):\n",
    "    fit_rsquareds = []\n",
    "    RMSEs = []\n",
    "    MAEs = []\n",
    "    SCorrs = []\n",
    "    pVals = []\n",
    "    print(\"\\nResults ({} features) :\".format(len(features)))\n",
    "    for i in range(n):\n",
    "        # Splitting the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(inputs, labels, test_size=0.2)\n",
    "        X_train1 = X_train[features].copy()\n",
    "        X_test1 = X_test[features].copy()     \n",
    "        # Fitting the model\n",
    "        X2 = sm.add_constant(X_train1)\n",
    "        est = sm.OLS(y_train, X2)\n",
    "        est2 = est.fit()\n",
    "        fit_rsquareds.append(est2.rsquared_adj)\n",
    "        # Making predictions\n",
    "        X2 = sm.add_constant(X_test1)\n",
    "        y_pred = est2.predict(X2)\n",
    "        # Re-transforming the outputs\n",
    "        if (output_transforms != None):\n",
    "            y_pred = output_transforms(y_pred)\n",
    "            y_test = output_transforms(y_test)\n",
    "        # Storing the results\n",
    "        RMSEs.append((mean_squared_error(y_test, y_pred, squared=False)))\n",
    "        MAEs.append((mean_absolute_error(y_test, y_pred)))\n",
    "        SCorrs.append(stats.spearmanr(y_test.to_numpy().reshape(y_test.shape[0],), y_pred.to_numpy())[0])\n",
    "        pVals.append(stats.spearmanr(y_test.to_numpy().reshape(y_test.shape[0],), y_pred.to_numpy())[1])\n",
    "    # Storing and printing the results\n",
    "    df = pd.DataFrame()\n",
    "    df['Adjusted R2'] = fit_rsquareds\n",
    "    df['RMSE'] = RMSEs\n",
    "    df['MAE'] = MAEs\n",
    "    df['Spearman Correlation'] = SCorrs\n",
    "    print()\n",
    "    print(\"Mean Adjusted R2 when fitting : {}\".format(np.mean((fit_rsquareds))))\n",
    "    print()\n",
    "    print(\"Mean RMSE : {}\".format(np.mean((RMSEs))))\n",
    "    print(\"Mean MAE : {}\".format(np.mean(MAEs)))\n",
    "    print(\"Mean Spearman Correlation : {}\".format(np.mean(SCorrs)))\n",
    "    print(\"Mean P-Value : {}\".format(np.mean(pVals)))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.read_csv(\"data/us_metrics_baseline.csv\")\n",
    "\n",
    "states = [\"california\",\"illinois\"]\n",
    "frames = []\n",
    "for i in states:\n",
    "    new_frame = pd.read_csv(\"data/indices_per_tract_\" + i + \".csv\")\n",
    "    frames.append(new_frame)\n",
    "indices_per_tract = pd.concat(frames).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the data per ward, and filtering wards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_indices = metrics.merge(indices_per_tract, on=\"tract\").drop(columns=['tract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i in range(metrics_indices.shape[0]):\n",
    "    if (metrics_indices['count'][i] < 5):\n",
    "        rows.append(i)\n",
    "metrics_indices = metrics_indices.drop(rows).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking the input and output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = metrics_indices.drop(['poverty','unemployment','education','income'],axis=1)\n",
    "y = metrics_indices[['education']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = X.copy()\n",
    "X_transformed['count'] = np.log(X_transformed['count'])\n",
    "\n",
    "y_transformed = y.copy()\n",
    "y_transformed = np.sqrt(y_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X_transformed), columns=['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = X_scaled.copy()\n",
    "y_ = y_transformed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_validate(X_, y_, 100, ['count'], np.square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the results to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"../data/temp_results/us_baseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking the input and output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = metrics_indices.drop(['poverty','unemployment','education','income'],axis=1)\n",
    "y = metrics_indices[['income']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering income output\n",
    " - Remove the rows with missing income\n",
    " - Set the top income to 250,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_remove = []\n",
    "for i in range(y.shape[0]):\n",
    "    if (y['income'][i] == \"-\"):\n",
    "        rows_to_remove.append(i)\n",
    "    elif (y['income'][i] == \"250,000+\"):\n",
    "        y['income'][i] = 250000\n",
    "X = X.drop(rows_to_remove).reset_index(drop=True)\n",
    "y = y.drop(rows_to_remove).reset_index(drop=True)\n",
    "y['income'] = y['income'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = X.copy()\n",
    "X_transformed['count'] = np.log(X_transformed['count'])\n",
    "\n",
    "y_transformed = y.copy()\n",
    "y_transformed = np.sqrt(y_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X_transformed), columns=['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = X_scaled.copy()\n",
    "y_ = y_transformed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_validate(X_, y_, 100, ['count'], np.square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the results to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"../data/temp_results/us_baseline_income.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
